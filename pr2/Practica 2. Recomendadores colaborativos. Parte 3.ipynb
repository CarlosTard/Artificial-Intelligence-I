{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carlos Tardón y Carlos Morán, grupo 9\n",
    "\n",
    "## Tercera parte.  Recomendacion basada en filtrado colaborativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tercera parte utilizaremos la librería SURPRISE Se puede consultar la documentacion en http://surpriselib.com/\n",
    "\n",
    "Para instalarla: conda install -c conda-forge scikit-surprise o pip install numpy pip install scikit-surprise\n",
    "\n",
    "La librería SurPRISE (Simple Python RecommendatIon System Engine) tiene algoritmos de predición de ratings incluidos: baseline algorithms, neighborhood methods, matrix factorization-based ( SVD, PMF, SVD++, NMF) y otros. También tiene predefinidas las medidas de similitud mas comunes sobre vectores (cosine, MSD, pearson…) Una de las cosas más utiles es que proporciona herramientas para evaluar, analizar y comparar el rendimiento de distitnos algoritmos. Lo que vamos a hacer en esta parte de la práctica es probar varios procedimientos de evaluación cruzada midiendo datos sobre errores entre el valor real (conocido) y la predicción del recomendador. Las siglas corresponden a las siguientes medidas:\n",
    "\n",
    "MAE: Mean Absolute Error\n",
    "RMSE: Root mean square error (RMSE)\n",
    "MSE: mean square error is defined as the expected value of the square of the difference between the estimator and the parameter. -square root of the mean square error.\n",
    "\n",
    "Vamos a ejecutar algunos recomendadores y evaluarlos para poder comentar los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9371  0.9301  0.9338  0.9282  0.9397  0.9338  0.0043  \n",
      "MAE (testset)     0.7367  0.7358  0.7355  0.7314  0.7398  0.7358  0.0027  \n",
      "Fit time          11.65   11.27   11.33   11.56   11.30   11.43   0.15    \n",
      "Test time         0.48    0.45    0.36    0.43    0.36    0.42    0.05    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93705508, 0.93007129, 0.93383281, 0.92821858, 0.93970594]),\n",
       " 'test_mae': array([0.73665742, 0.73577396, 0.73552484, 0.7313606 , 0.73977581]),\n",
       " 'fit_time': (11.65084719657898,\n",
       "  11.273847818374634,\n",
       "  11.332695245742798,\n",
       "  11.56409764289856,\n",
       "  11.30376672744751),\n",
       " 'test_time': (0.4767286777496338,\n",
       "  0.45079898834228516,\n",
       "  0.35704588890075684,\n",
       "  0.43282246589660645,\n",
       "  0.36103367805480957)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ejemplo getting started de la documentación de SURPRISE\n",
    "##http://surpriselib.com/\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluacion extracted from surprise: \n",
    "# https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-compute-precision-k-and-recall-k\n",
    "def measures_at_k(predictions, k, th_recom, th_relev):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    onehits = dict()\n",
    "    mrr = dict()\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        \n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= th_relev) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= th_recom) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= th_relev) and (est >= th_recom))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "       \n",
    "        \n",
    "    return precisions, recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(precision, recall):\n",
    "    \"\"\"\n",
    "        Funcion que calcula el f1 (media armónica) en funcion de precision y recall\n",
    "    \"\"\"\n",
    "    denominador = precision + recall\n",
    "    \n",
    "    if denominador == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * precision * recall) / denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(recommendations, k, knn):\n",
    "    \"\"\"\n",
    "        Function to get the measures results \n",
    "    \"\"\"\n",
    "    # threshold = 4 --> solo se tienen en cuenta peliculas que hayan \n",
    "    # sido puntuadas con 4 o 5 estrellas\n",
    "    precisions, recalls  = measures_at_k(recommendations, k, th_recom=4, th_relev=1)\n",
    "    \n",
    "    # Measures can then be averaged over all users\n",
    "    precision_result = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall_result = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    # Media armónica  \n",
    "    f1_result = f1(precision_result, recall_result)\n",
    "    # En este archivo se volcarán los resultados de las métricas. Tiene que existir. \n",
    "    f = open(\"results_user_cf.csv\", 'a')\n",
    "    #f = open(\"C:/hlocal/results_user_cf.csv\", 'a')\n",
    "    f.write(str(k) + ',' + knn + \",\" + str(precision_result) + ',' + str(recall_result) + ',' +  str(f1_result) +  '\\n') \n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hemos cargado antes los datos de movieLens para 100K\n",
    "# data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo dos conjuntos de datos, el training set y el evaluation set\n",
    "# cada uno contendra la mitad de los datos\n",
    "training_set, evaluation_set = train_test_split(data, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora determino cual es el algoritmo que voy a usar de recomendacion\n",
    "# en este caso voy a usar el algoritmo KNN para encontrar las similitudes entre items\n",
    "recommendation_algorithm = KNNBasic(k=100, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "#print(recommendation_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1f25637f640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplico el algoritmo sobre el training_set\n",
    "recommendation_algorithm.fit(training_set)\n",
    "#print(recommendation_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplico el algoritmo sobre el evaluation set y obtengo las predicciones en las recomendaciones\n",
    "recommendations = recommendation_algorithm.test(evaluation_set)\n",
    "#print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "for k in range(K):\n",
    "    get_results(recommendations, k+1, \"knn_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Hacer distintas pruebas con el resto de tipos KNN\n",
    "recommendation_algorithm = KNNWithMeans(k=100, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "\n",
    "# aplico el algoritmo sobre el training_set\n",
    "recommendation_algorithm.fit(training_set)\n",
    "\n",
    "# aplico el algoritmo sobre el evaluation set y obtengo las predicciones en las recomendaciones\n",
    "recommendations = recommendation_algorithm.test(evaluation_set)\n",
    "\n",
    "K = 10\n",
    "for k in range(K):\n",
    "    get_results(recommendations, k+1, \"knn_withmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Hago lo mismo con el resto de tipos KNN\n",
    "recommendation_algorithm = KNNWithZScore(k=100, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "\n",
    "# aplico el algoritmo sobre el training_set\n",
    "recommendation_algorithm.fit(training_set)\n",
    "\n",
    "# aplico el algoritmo sobre el evaluation set y obtengo las predicciones en las recomendaciones\n",
    "recommendations = recommendation_algorithm.test(evaluation_set)\n",
    "\n",
    "K = 10\n",
    "for k in range(K):\n",
    "    get_results(recommendations, k+1, \"knn_withzscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Hago lo mismo con el resto de tipos KNN\n",
    "recommendation_algorithm = KNNBaseline(k=100, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "\n",
    "# aplico el algoritmo sobre el training_set\n",
    "recommendation_algorithm.fit(training_set)\n",
    "\n",
    "# aplico el algoritmo sobre el evaluation set y obtengo las predicciones en las recomendaciones\n",
    "recommendations = recommendation_algorithm.test(evaluation_set)\n",
    "\n",
    "K = 10\n",
    "for k in range(K):\n",
    "    get_results(recommendations, k+1, \"knn_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio:  se pide ejecutar, comprender y escribir comentarios razonados sobre la evaluación de distintos recomendadores.\n",
    "    \n",
    "Prueba otros algoritmos de predicción de ratings basados en la estimación de los vecinos más próximos y realiza evaluaciones de su comportamiento. Comenta los resultados.¶\n",
    "Puedes consultar la documentación en https://surprise.readthedocs.io/en/stable/knn_inspired.html#\n",
    "\n",
    "\n",
    "#### Explicación de cada recomendador\n",
    "Los 4 recomendadores que aquí estudiamos (KNNBasic, KNNWithZScore, KNNWithMeans, KNNBaseline) se derivan del enfoque KNN, donde la estimación del recomendador se calcula agregando los valores de los k vecinos más próximos. La diferencia entre estos 4 estimadores está en la forma de agregar estas valoraciones.\n",
    "\n",
    "En el KNNBasic, los valores se agregan haciendo una media ponderada por la similitud. Por tanto, los vecinos más similares(más cercanos) tendrán una mayor influencia en el resultado final. Destaca por su sencillez.\n",
    "\n",
    "En KNNWithMeans, se hace una media ponderada por la similitud, pero no de los valores de los vecinos, sino de las distancias entre esos valores y su media.  \n",
    "\n",
    "En KNNWithZScore se hace una media ponderada de los z-score, es decir, de la unidad tipificada(restando la media y dividiendo entre la desviación típica)\n",
    "\n",
    "Por último, KNNBaseline es una aproximación parecida a KNNWithMeans, pero en vez de la media usa un _baseline_ con el objetivo de mejorar la recomendación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparemos el comportamiento de los algoritmos\n",
    "Primero, realizaremos una validación cruzada con las medidas RMSE y MAE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9971  1.0041  1.0053  1.0015  0.9951  1.0006  0.0040  \n",
      "MAE (testset)     0.7878  0.7920  0.7949  0.7945  0.7883  0.7915  0.0030  \n",
      "Fit time          1.33    1.19    1.60    1.56    1.57    1.45    0.16    \n",
      "Test time         4.68    5.12    5.97    6.05    5.92    5.55    0.55    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.99706653, 1.00414383, 1.0053323 , 1.0014597 , 0.99506959]),\n",
       " 'test_mae': array([0.78782037, 0.79204042, 0.79488668, 0.79450741, 0.78830258]),\n",
       " 'fit_time': (1.3285479545593262,\n",
       "  1.1863369941711426,\n",
       "  1.602675199508667,\n",
       "  1.5630590915679932,\n",
       "  1.5683982372283936),\n",
       " 'test_time': (4.680873155593872,\n",
       "  5.116900205612183,\n",
       "  5.971094369888306,\n",
       "  6.04677152633667,\n",
       "  5.9150230884552)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNBasic(k=100, verbose=False, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9410  0.9323  0.9453  0.9379  0.9313  0.9376  0.0053  \n",
      "MAE (testset)     0.7308  0.7261  0.7350  0.7308  0.7256  0.7297  0.0035  \n",
      "Fit time          1.85    1.81    1.74    1.80    1.67    1.78    0.06    \n",
      "Test time         7.04    6.85    6.95    7.11    7.21    7.03    0.12    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94101757, 0.93232102, 0.9452835 , 0.93791477, 0.93131122]),\n",
       " 'test_mae': array([0.73075351, 0.72609902, 0.7350499 , 0.73079929, 0.72560364]),\n",
       " 'fit_time': (1.8545176982879639,\n",
       "  1.813765048980713,\n",
       "  1.740574598312378,\n",
       "  1.8017897605895996,\n",
       "  1.6682560443878174),\n",
       " 'test_time': (7.0405566692352295,\n",
       "  6.853313207626343,\n",
       "  6.949240684509277,\n",
       "  7.106757402420044,\n",
       "  7.210302114486694)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNWithZScore(k=100, verbose=False, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9479  0.9561  0.9473  0.9553  0.9569  0.9527  0.0042  \n",
      "MAE (testset)     0.7450  0.7508  0.7440  0.7511  0.7507  0.7483  0.0032  \n",
      "Fit time          1.37    1.42    1.50    1.47    1.38    1.43    0.05    \n",
      "Test time         7.28    7.40    7.85    7.35    7.53    7.48    0.20    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94793427, 0.95611606, 0.94730487, 0.95531864, 0.95685222]),\n",
       " 'test_mae': array([0.74503644, 0.7508304 , 0.74395504, 0.75112569, 0.75074185]),\n",
       " 'fit_time': (1.365238904953003,\n",
       "  1.415797233581543,\n",
       "  1.4987385272979736,\n",
       "  1.4682555198669434,\n",
       "  1.3806555271148682),\n",
       " 'test_time': (7.281141042709351,\n",
       "  7.4013354778289795,\n",
       "  7.84873628616333,\n",
       "  7.350979328155518,\n",
       "  7.529534578323364)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos con la similitud del coseno. Empeora el error cuadratico medio\n",
    "algo = KNNWithZScore(k=100, verbose=False, sim_options={'name': 'cosine', 'user_based': True})\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9570  0.9502  0.9548  0.9560  0.9583  0.9553  0.0028  \n",
      "MAE (testset)     0.7562  0.7462  0.7556  0.7507  0.7571  0.7531  0.0041  \n",
      "Fit time          1.39    1.54    1.30    1.46    1.30    1.40    0.09    \n",
      "Test time         6.67    7.40    6.79    6.55    6.67    6.82    0.30    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.95703715, 0.95022226, 0.95480904, 0.95603234, 0.95834078]),\n",
       " 'test_mae': array([0.75616416, 0.74617468, 0.75556051, 0.75065941, 0.75705995]),\n",
       " 'fit_time': (1.391956090927124,\n",
       "  1.5360965728759766,\n",
       "  1.2973341941833496,\n",
       "  1.4586527347564697,\n",
       "  1.2995209693908691),\n",
       " 'test_time': (6.671422004699707,\n",
       "  7.404827356338501,\n",
       "  6.7909135818481445,\n",
       "  6.548822641372681,\n",
       "  6.66856837272644)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNWithMeans(k=100, verbose=False, sim_options={'name': 'cosine', 'user_based': True})\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9211  0.9246  0.9271  0.9188  0.9167  0.9216  0.0038  \n",
      "MAE (testset)     0.7223  0.7241  0.7270  0.7191  0.7189  0.7223  0.0031  \n",
      "Fit time          1.52    1.54    1.73    1.69    1.58    1.61    0.08    \n",
      "Test time         7.67    7.85    7.66    7.24    7.74    7.64    0.21    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.9211128 , 0.92456164, 0.92705595, 0.91878244, 0.91671799]),\n",
       " 'test_mae': array([0.72226533, 0.72408205, 0.72696128, 0.71908342, 0.71890669]),\n",
       " 'fit_time': (1.5238189697265625,\n",
       "  1.5369915962219238,\n",
       "  1.7276537418365479,\n",
       "  1.6889476776123047,\n",
       "  1.57944655418396),\n",
       " 'test_time': (7.6736791133880615,\n",
       "  7.854694604873657,\n",
       "  7.662973642349243,\n",
       "  7.241253852844238,\n",
       "  7.742943048477173)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probamos el último tipo de KNN. Es el que mejor error cuadrático medio posee, con RMSE 0.9216 y MAE 0.7223\n",
    "algo = KNNBaseline(k=100, verbose=False, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados obtenidos\n",
    "\n",
    "A continuación ofrecemos los datos extraídos del fichero csv. \n",
    "\n",
    "<table style=\"width:80%\">\n",
    "<tr border=\"bottom\">\n",
    "<td align=\"center\">Algoritmo</td>\n",
    "<td align=\"center\">k</td>\n",
    "<td align=\"center\">Precisión</td>\n",
    "<td align=\"center\">Recall</td>\n",
    "<td align=\"center\">f1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\"> KNNBasic </td>\n",
    "    <td>1</td>\n",
    "<td>0.9565217391304348</td>\n",
    "<td>0.03736769319682807</td>\n",
    "<td>0.07192552757146778</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>6</td>\n",
    "<td>0.9565217391304348</td>\n",
    "<td>0.12516194862022245</td>\n",
    "<td>0.22135884292777913</td>\n",
    "</tr>\n",
    "    <tr>\n",
    "    <td>10</td>\n",
    "<td>0.9565217391304348</td>\n",
    "<td>0.1757298050936013</td>\n",
    "<td>0.2969117236230051</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"5\", style=\"height:50px\"></td>\n",
    "    </tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\"> KNN_withmeans </td>\n",
    "  <td>1</td>\n",
    "<td>0.8324496288441146</td>\n",
    "<td>0.03173731545381958</td>\n",
    "<td>0.06114352142059743</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>6</td>\n",
    "<td>0.8324496288441146</td>\n",
    "<td>0.12438017987038016</td>\n",
    "<td>0.21642351361893494</td>\n",
    "</tr>\n",
    "    <tr>\n",
    "    <td>10</td>\n",
    "<td>0.8324496288441146</td>\n",
    "<td>0.19618169995117293</td>\n",
    "<td>0.3175314201281977</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"5\", style=\"height:50px\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\"> KNN_withzscore </td>\n",
    "    <td>1</td>\n",
    "<td>0.8472958642629904</td>\n",
    "<td>0.03222569512002612</td>\n",
    "<td>0.06208988945615473</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>6</td>\n",
    "<td>0.8472958642629904</td>\n",
    "<td>0.12460074322957036</td>\n",
    "<td>0.21725293330302703</td>\n",
    "</tr>\n",
    "    <tr>\n",
    "    <td>10</td>\n",
    "<td>0.8472958642629904</td>\n",
    "<td>0.19663515433795892</td>\n",
    "<td>0.31919379742648424</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"5\", style=\"height:50px\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\"> KNN_baseline </td>\n",
    "     <td>1</td>\n",
    "<td>0.9257688229056203</td>\n",
    "<td>0.03694134380519141</td>\n",
    "<td>0.07104764352479713</td>\n",
    "</tr>\n",
    "<tr>\n",
    "     <td>6</td>\n",
    "<td>0.9257688229056203</td>\n",
    "<td>0.13287370326098252</td>\n",
    "<td>0.23239257600666582</td>\n",
    "</tr>\n",
    "    <tr>\n",
    "     <td>10</td>\n",
    "<td>0.9257688229056203</td>\n",
    "<td>0.19126218212339602</td>\n",
    "<td>0.31702712711387493</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación y comparación\n",
    "\n",
    "Lo primero que observamos es la diferencia de valores entre Precision y Recall. Mientras que Precision se mantiene siempre por encima de 0.83, recall no supera el 0.15 en ningún caso. Este comportamiento es esperable. En un recomendador, nos interesa que las películas que recomendamos al usuario le gusten lo más posible, y es exactamente esto lo que mide la métrica precisión, es decir, la fracción de las películas recomendadas que son relevantes. En cambio, la métrica recall mide la fracción de items relevantes que son recomendados. Esta métrica no es tan relevante en este caso, pues mejorarla solo aumentaría el número total de recomendaciones que podemos darle al usuario. Por tanto, con que el recall se mantenga por encima de un umbral es suficiente.\n",
    "\n",
    "Como vemos, los algoritmos que otorgan mejores resultados en cuanto a precisión y recall son knn_basic y knn_baseline. Además, knn_baseline era el que minimizaba las medidas 'RMSE'y 'MAE', así que nos quedamos con knn_baseline para hacer comparaciones con el resto de recomendadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9386  0.9404  0.9386  0.9305  0.9385  0.9373  0.0035  \n",
      "MAE (testset)     0.7384  0.7409  0.7403  0.7332  0.7393  0.7384  0.0028  \n",
      "Fit time          11.51   11.53   10.93   10.91   10.96   11.17   0.29    \n",
      "Test time         0.38    0.44    0.43    0.34    0.43    0.40    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93855379, 0.9403645 , 0.93861045, 0.93045034, 0.93853057]),\n",
       " 'test_mae': array([0.73843435, 0.74090468, 0.7403104 , 0.73318345, 0.7393197 ]),\n",
       " 'fit_time': (11.508193492889404,\n",
       "  11.527180194854736,\n",
       "  10.928775310516357,\n",
       "  10.90683913230896,\n",
       "  10.960696458816528),\n",
       " 'test_time': (0.3819754123687744,\n",
       "  0.44081854820251465,\n",
       "  0.4298527240753174,\n",
       "  0.3390960693359375,\n",
       "  0.4308464527130127)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El algoritmo SVD,que está basado en factorización de matrices\n",
    "algo = SVD() # Creamos el objeto svd, con parámetros por defecto\n",
    "\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, evaluation_set = train_test_split(data, test_size=.5)\n",
    "algo.fit(training_set)\n",
    "\n",
    "recommendations = algo.test(evaluation_set)\n",
    "\n",
    "for k in [1,6,10]:\n",
    "    get_results(recommendations, k, \"SVD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9471  0.9403  0.9549  0.9378  0.9426  0.9445  0.0060  \n",
      "MAE (testset)     0.7461  0.7362  0.7488  0.7376  0.7442  0.7426  0.0049  \n",
      "Fit time          1.76    1.83    1.89    1.81    1.91    1.84    0.05    \n",
      "Test time         6.88    7.27    7.46    7.30    7.39    7.26    0.20    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94707839, 0.94031413, 0.95489261, 0.93775036, 0.94259978]),\n",
       " 'test_mae': array([0.7460805 , 0.73615954, 0.74880279, 0.7376372 , 0.74423424]),\n",
       " 'fit_time': (1.7602977752685547,\n",
       "  1.8261158466339111,\n",
       "  1.885951042175293,\n",
       "  1.8131506443023682,\n",
       "  1.9138834476470947),\n",
       " 'test_time': (6.875615835189819,\n",
       "  7.267587184906006,\n",
       "  7.4590537548065186,\n",
       "  7.298485517501831,\n",
       "  7.389246463775635)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.prediction_algorithms.slope_one import SlopeOne\n",
    "\n",
    "algo = SlopeOne()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.fit(training_set)\n",
    "\n",
    "recommendations = algo.test(evaluation_set)\n",
    "\n",
    "for k in [1,6,10]:\n",
    "    get_results(recommendations, k, \"SlopeOne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9675  0.9591  0.9636  0.9677  0.9573  0.9630  0.0043  \n",
      "MAE (testset)     0.7609  0.7536  0.7577  0.7582  0.7526  0.7566  0.0031  \n",
      "Fit time          13.28   13.37   13.40   13.21   13.38   13.33   0.07    \n",
      "Test time         0.44    0.30    0.43    0.28    0.39    0.37    0.07    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.96754163, 0.95907227, 0.96358748, 0.96766932, 0.95732019]),\n",
       " 'test_mae': array([0.76094016, 0.75355091, 0.75773667, 0.75815169, 0.75261421]),\n",
       " 'fit_time': (13.28148341178894,\n",
       "  13.370248794555664,\n",
       "  13.400166511535645,\n",
       "  13.210677862167358,\n",
       "  13.380219459533691),\n",
       " 'test_time': (0.4418184757232666,\n",
       "  0.3041844367980957,\n",
       "  0.42586374282836914,\n",
       "  0.275266170501709,\n",
       "  0.38696861267089844)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import NMF\n",
    "# Algoritmo parecido a SVD. También basado en el producto de matrices\n",
    "algorithm = NMF()\n",
    "cross_validate(algorithm, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.fit(training_set)\n",
    "\n",
    "recommendations = algorithm.test(evaluation_set)\n",
    "\n",
    "for k in [1,6,10]:\n",
    "    get_results(recommendations, k, \"NMF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados obtenidos\n",
    "\n",
    "A continuación ofrecemos los datos extraídos del fichero csv:\n",
    "\n",
    "<table style=\"width:75%\">\n",
    "<tr border=\"bottom\">\n",
    "<td align=\"center\">Algoritmo</td>\n",
    "<td align=\"center\">k</td>\n",
    "<td align=\"center\">Precisión</td>\n",
    "<td align=\"center\">Recall</td>\n",
    "<td align=\"center\">f1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\"> SVD </td>\n",
    "    <td>1</td>\n",
    "<td>0.8441145281018028</td>\n",
    "<td>0.03169942129583380</td>\n",
    "<td>0.0611041695936367</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>6</td>\n",
    "<td>0.8441145281018028</td>\n",
    "<td>0.12788856550036207</td>\n",
    "<td>0.2221239764101800</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>10</td>\n",
    "<td>0.8441145281018028</td>\n",
    "<td>0.16773051771603772</td>\n",
    "<td>0.2798526659696334</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"4\", style=\"height:50px\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\"> Slope One </td>\n",
    "    <td>1</td>\n",
    "<td>0.8324496288441146</td>\n",
    "<td>0.03048242326547522</td>\n",
    "<td>0.05881130935299061</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>6</td>\n",
    "<td>0.8324496288441146</td>\n",
    "<td>0.13285433299852145</td>\n",
    "<td>0.22913930651199530</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>10</td>\n",
    "<td>0.8324496288441146</td>\n",
    "<td>0.17973879658309724</td>\n",
    "<td>0.29564355953060006</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"4\", style=\"height:50px\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\"> NMF </td>\n",
    "    <td>1</td>\n",
    "<td>0.8706256627783670</td>\n",
    "<td>0.03338207198485823</td>\n",
    "<td>0.06429876079399810</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>6</td>\n",
    "<td>0.8706256627783670</td>\n",
    "<td>0.14204241678755442</td>\n",
    "<td>0.24423752610295515</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>10</td>\n",
    "<td>0.8706256627783670</td>\n",
    "<td>0.18431278701594284</td>\n",
    "<td>0.30422143090067655</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación y comparación\n",
    "\n",
    "Vemos que, tanto las métricas 'RMSE' y 'MAE', como la Precisión y el Recall son ligeramente peores a las obtenidas con KNN_Baseline en los casos del SVD y SlopeOne. Por otro lado, aunque la precisión mejora ligeramente en el caso del NMF, empeoran las métricas 'RMSE' y 'MAE' con respecto a los dos anteriores. Deducimos que NMF empeora al SVD y, por lo tanto, al KNN_Baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
